 # Описание задачи

  При поиске новых клиентов СИБУРу приходится обрабатывать информацию о миллионах новых компаний из различных источников. Названия компаний при этом могут иметь разное написание, содержать сокращения или ошибки, быть аффилированными с компаниями, уже известными СИБУРу.
  
  Для более эффективной обработки информации о потенциальных клиентах, СИБУРу необходимо знать, связаны ли два названия (т.е. принадлежат одной компании или аффилированным компаниям). В этом случае СИБУР сможет использовать уже известную информацию о самой компании или об аффилированных компаниях, не дублировать обращения в компанию или не тратить время на нерелевантные компании или дочерние компании конкурентов.
  
  Тренировочная выборка содержит пары названий из разных источников (в том числе, пользовательских) и разметку. Разметка получена частично вручную, частично - алгоритмически. Кроме того, разметка может содержать ошибки. Вам предстоит построить бинарную модель, предсказывающую, являются ли два названия связанными. Метрика, используемая в данной задаче - F1.
  
  В этой задаче можно и даже нужно пользоваться открытыми источниками данных для обогащения датасета или поиска дополнительной важной для определения аффилированных компаний информации.


Ссылка на страницу организатора соревнования [здесь](https://sibur.ai-community.com/competitions/4/tasks/12)


Данные для обучения и тестирования - train.zip, test.zip

# Есть несколько решений задачи (Jupyter Notebook):
 - Финальное решение, отправленное на паблик с "запрещенным" приемом:  
 *Название файла: **201211_pap_SIBUR_06699.ipynb***  
 *f1-score = **0.7036** на паблике  
 **[Место](https://sibur.ai-community.com/competitions/4/tasks/12/rating): 28**  
Файл с правильными ответами - submission_lgbm_and_deep_tree.csv

- Дополнительное решение, подготовленное после завершения соревнования:  
*Название файла: **201227_pap_SIBUR.ipynb***  
*f1-score = **0.6497*** (на приватном лидер-борде решение не отображается, так как оно подано уже после завершения соревнования)

# Рассмотрим этапы исследования, с f1-score = 0.7036
**Предобработка данных**
1. Переведем все символы из текста в нижний регистр
2. Удалим названия стран
3. Удалим знаки и спецсимволы
4. Составим ручной список стоп-слов и удалим стоп-слова
5. Проведем транслитерацию
6. Составим список высокочастотных слов
7. Удалим 50 наиболее высокочастотных слов

**Генерация и анализ фич**
1. Создадим признак: отметка 0, если в названиях обоих компаний пусто (то есть наша предобработка привела к полному удалению слов из названия компании)
2. Посчитаем дистанцию Левенштейна между названиями каждой пары компаний, а также нормированную дистанцию Левенштейна
3. Посчитаем количество повторяющихся и различных слов в названиях компаний, а также сумму символов повторяющихся и различных слов
4. Определим среднее значение символов с повторяющихся и различающихся словах
5. Вычислим коэффициент отношения количества совпадающих слов к количеству различных слов
6. Используя словарь названий промышленных холдингов, который составлен как по результатам анализа ошибок алгоритма, так и по результатам определения индекса джинни признаков сумм высокочастотных слов в паре названий, определим совпадающие слова в списке названий холдингов и названий компаний в паре
7. Определим для каждого из 650-ти высокочастотных слов колчество его появлений в паре названий компаний
8. Определим общее количество высокочастотных слов в паре названий компаний
9. Определим долю высокочастотных слов в паре названий компаний к общему колчеству слов в паре
10. Удалим 300 высокочастотных слов, зате вычислим новые дистанции Левенштейна, отметим пустые пары как 0 и рассчитаем отношение между дистанцией Левенштейна и пустыми парами

**Моделирование**
1. Строим модель light gbm на всех признаках, кроме суммы каждого высокочастотного слова. Выбираем лучшие признаки. Строим модель на них.
2. Используем полученный прогноз (0 или 1) в моделе deep decission tree. В модель также добавляем 650 признаков (количество в паре каждого из 650-ти высокочастотного слова)
3. Оцениваем прогноз по матрице ошибок, визуально. Смотрим на прогноз на тестовой выборке: баланс классов, таблицы для связанных и различных компаний

# Рассмотрим этапы исследования, с f1-score = 0.6497
**Предобработка данных или токенизация по словам**
1. Переведем символы в нижний регистр
2. Удалим спецсимволы, знаки препинания (всё кроме букв и цифр)
3. Проведем транслитерацию
4. Составим список стоп-слов и удалим стоп-слова (названия стран, столиц, крупных городов, геогафических объектов и др.)

**Анализ высокочастотных слов**
1. Создадим словарь встречаемости слов (кол-во употреблений каждого уникального слова в тексте)
2. Визуализируем словарь встречаемости слов с помощью **word cloud**
3. Создадим матрицу 650 наиболее встречаемых слов (650*650)
4. Создадим датасет, в котором каждая пара названий организаций с определенной целевой меткой (0 или 1) сопостовляется с количеством употреблений каждого слова из 650 наиболее встречаемых слов 
5. Определим наиболее значимые по индексу Джинни слова из 650 (**Light GBM**)
6. Создадим первый список названий организаций (холдингов)
7. Визуализируем словарь встречаемости слов только для пары названий организаций с целевой меткой 1 (дубликаты)
8. Создадим второй список названий организаций (холдингов)
9. Объединим списки названий организаций (холдингов)
10. Исключим из словаря встречаемости слов названия организаций и холдингов. 
11. В итоге получим словарь встречаемости слов без названий организаций

**Создание признакового пространства**
1. Создадим 6 датасетов, которые будут использоваться в построении прогнозной модели бинарной классификации объектов (0 или 1).  
Каждый датасет состоит из названий организаций для пар объектов (слов) за вычетом выскочастотных слов по установленному порогу частоты употребления.  
Используем следующие пороги: 50, 200, 250, 300, 350, 500
2. Для каждого датасета создадим признаковое пространство следующим образом:

    2.1. Определим **метрики наиболее значимых дистанций:**  

      *Create label if both of cells are empty:*  
       - **label** if the both names of companies have zero words (they are empty):  
               - label 0 when here is empty in names of companies  
               - label 1 else

      *Count Levenstein and normilized Levenstein distances:*
       - **levenstein** distance after drop all selected high-frequency words
       - **Normalized levenstein** distance

      *Count Jaro-Winkler distance:*
       - **Jaro Winkler distance** after drop all selected high-frequency words

      *Count distance metric based on Longest Common Subsequence:*
       - **Distance LCS** after drop all selected high-frequency words

      *Ratios:*
       - ratio between **levenstein** distance and **label 0** if names are empty
       - ratio between **normalized levenstein** distance and **label 0**
       - ratio between **jaro** distance and **label 0**
       - ratio between **distance LCS** and **label 0**

2.2. Оцифруем **информацию о схожести и различии слов и символов:**
*Similar and dudplicate words*
 - **duplct_wrds** - count of duplicate words
 - **duplct_smbls** - the sum of the_symbols in duplicate words
 - **frst_s** - the sum of the first repeated symbols
 - **last_s** - the sum of the last repeated symbols


*Different words*
 - **dif_wrds** - count of different words
 - **dif_smbls** - sum of symbols in duplicate words
 
 
*Labels*
 - **subset** - if one name contain all the words of another in the beginning sign it 1, else 0
 - **subsetr** - if one name contain all the words of another sign it 1, else 0
 
*Additional*
 - **sum_wrds** - sum of count of the duplicate and different words
 - **sum_smbls** - sum of all symbols in the names of companies
 
*Subtraction*
 - **subtr_wrds** - differences between count of duplicate and different words
 - **subtr_symb** - differences between the sum of the symbols in duplicate and different words
 
*Ratios*
 - **avg_smbls_duplct** - ratio between sum of symbols and count of duplicate words. Else can say: average number of symbols in a duplicate word;
 - **avg_smbls_dif** - ratio between sum of symbols and count of different words. Else can say: average number of symbols in a different word;
 - **avg_frst_s** - ratio between the sum of the first repeated symbols and sum of the all symbols in the name of company
 - **avg_last_s** - ratio between the sum of the last repeated symbols and sum of the all symbols in the name of company 
 - **rt_dplct_to_dif_wrds** - ratio between count of duplicate and different words in the pair
 - **rt_dplct_to_sum_wrds** - ratio between count of duplicate and all words in the pair

3.Объединяем датасеты с признаковым пространством
